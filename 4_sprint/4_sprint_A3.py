# https://contest.yandex.ru/contest/24414/run-report/149030803/

# -- ПРИНЦИП РАБОТЫ ---
#(1)
# При вводе данных, сразу создаем словарь словарей. В нем храним как ключи все слова,
# что подаются на вход. Дальше будем работать только с ним. Значения ключей это также словарь,
# где ключи - порядковые номера предложений. где встретилось слово. а значение - количество раз.
#(2)
# Отфильтровываем те слова конкретного запроса, что встречаются в общем списке слов (их может и не быть)
#(3)
# Проходимся по отобранным словам конкретного запроса. Группируем по номерам документов. Считаем накопительную релевантность.

# -- ДОКАЗАТЕЛЬСТВА КОРРЕКТНОСТИ --
# Фактически мы перебираем все слова всех предложений. что падаются на входе со всеми словами запросов.
# Только для каждого запроса мы работаем с конкретным и ограниченным перечнем предложений, а не каждый раз со всем.

# -- ОПРЕДЕЛЕНИЕ СЛОЖНОСТИ АЛГОРИТМА --
# Временная сложность очень грубо O(n) - чтобы построить главный общий словарь словарей.
# Пространственная сложность O(n)  - наихудший случай, когда n - общее количество входных уникальных слов от всех входных предложений



from collections import defaultdict, Counter

def building_index(n, letter_list):
    """Отдельно создаем индекс всех-всех слов"""
    # (1) ЗА ОДИН ПРОХОД ПО ВХОДНЫМ ДАННЫМ СОЗДАЕМ ЕДИНЫЙ СЛОВАРЬ ПО ВСЕМ УНИКАЛЬНЫМ СЛОВАМ,
    # где ключ - само слово, а значение также словарик, где ключ - номер предложения, где встретилось слово, а значение - количество раз
    # {'i': {0: 1}, 'love': {0: 1}, 'coffee': {0: 1, 1: 1}}

    index = defaultdict(dict)

    # проходимся по кортежам (номер предложения, список слов предложения)
    for doc_id, letter_words in enumerate(letter_list):

        # Автоподсчет количества встречаемых слов (словарь, где ключ - уникальное слово, значение - сколько раз оно встретилось в подаваемом предложении)
        letter_word_counts_dict = Counter(letter_words)

        # добавляем в общий словарь статистику для слова + где и сколько раз оно встречается
        for word, count in letter_word_counts_dict.items():
            index[word][doc_id] = count

    return index



def find_relevant_documents(index, m, query_letter_set):
    """
    Для каждого запроса выведите на одной строке номера пяти самых релевантных документов.
    Если нашлось менее пяти документов, то выведите столько, сколько нашлось.
    Документы с релевантностью 0 выдавать не нужно.

    Подумайте над случаями, когда запросы состоят из слов,
    встречающихся в малом количестве документов.

    Что если одно слово много раз встречается в одном документе?
    """


    # (2) Фильтруем слова запроса. Что они действительно есть в общем списке слов
    finded_letters_words = set()  # итоговое множество слов запроса, что нашлись в общих словах
    for word in query_letter_set:
        if word in index:  # слово из запроса может и не быть в общем словаре входных предложений
            finded_letters_words.add(word)


    # (3) Для каждого отфильтрованного слова запроса проходимся по тем документам, где оно встречается и собираем счетчики
    scores_dict = defaultdict(int)  # ключ - номер документа, значение - накопительная релевантность
    for word in finded_letters_words:  # слова отфильтрованного множества запроса
        if word in index:
            for doc_id, count in index[word].items():
                scores_dict[doc_id] += count

    # (4) перегоняем элементы словаря в список кортежей, нулевые не берем
    scores = []
    for doc_id, relevance in scores_dict.items():
        if relevance > 0:
            scores.append((-relevance, doc_id))


    # (5)
    # Сортируем и берем топ-5
    scores.sort()
    top_letters = []
    for score, letter_id in scores[:5]:
        # Номера документов в выводе начинаются с 1
        top_letters.append(str(letter_id + 1))

    print(*top_letters, sep=' ')








if __name__ == '__main__':

    n = int(input().strip())  # количество документов в базе

    letter_list = []  # список с подаваемыми предложениями
    for i in range(n):
        letter = input().strip().split(' ')
        letter_list.append(letter)  # список списков

    index = building_index(n, letter_list)

    m = int(input().strip())  # число запросов
    query_letter_list = []  # список с подаваемыми запросами
    for i in range(m):
        query_letter_set = set(input().strip().split(' '))  # ЗДЕСЬ УЖЕ МНОЖЕСТВО - УНИКАЛЬНЫЕ СЛОВА ЗАПРОСА
        # прочитанный запрос СРАЗУ обрабатываем
        find_relevant_documents(index, m, query_letter_set)